{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/KuzmaKhrabrov/character-tokenizer.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-22T15:18:06.784805Z","iopub.execute_input":"2023-11-22T15:18:06.785764Z","iopub.status.idle":"2023-11-22T15:18:07.791664Z","shell.execute_reply.started":"2023-11-22T15:18:06.785726Z","shell.execute_reply":"2023-11-22T15:18:07.790579Z"},"trusted":true},"execution_count":98,"outputs":[{"name":"stdout","text":"fatal: destination path 'character-tokenizer' already exists and is not an empty directory.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:18:07.793734Z","iopub.execute_input":"2023-11-22T15:18:07.794088Z","iopub.status.idle":"2023-11-22T15:18:19.207249Z","shell.execute_reply.started":"2023-11-22T15:18:07.794059Z","shell.execute_reply":"2023-11-22T15:18:19.206143Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n","output_type":"stream"}]},{"cell_type":"code","source":"import string\nimport sys\nsys.path.append(\"character-tokenizer\")\nfrom charactertokenizer import CharacterTokenizer\n\nchars = \"АаБбВвГгДдЕеЁёЖжЗзИиЙйКкЛлМмНнОоПпРрСсТтУуФфХхЦцЧчШшЩщЪъЫыЬьЭэЮюЯя\"\nmodel_max_length = 64\ntokenizer = CharacterTokenizer(chars, model_max_length)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:18:19.209303Z","iopub.execute_input":"2023-11-22T15:18:19.209620Z","iopub.status.idle":"2023-11-22T15:18:19.216543Z","shell.execute_reply.started":"2023-11-22T15:18:19.209592Z","shell.execute_reply":"2023-11-22T15:18:19.215557Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"len(chars)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:18:19.217785Z","iopub.execute_input":"2023-11-22T15:18:19.218686Z","iopub.status.idle":"2023-11-22T15:18:19.231157Z","shell.execute_reply.started":"2023-11-22T15:18:19.218659Z","shell.execute_reply":"2023-11-22T15:18:19.230339Z"},"trusted":true},"execution_count":101,"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"66"},"metadata":{}}]},{"cell_type":"code","source":"example = \"Привет\"\ntokens = tokenizer(example)\nprint(tokens)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:18:19.233335Z","iopub.execute_input":"2023-11-22T15:18:19.233614Z","iopub.status.idle":"2023-11-22T15:18:19.242524Z","shell.execute_reply.started":"2023-11-22T15:18:19.233589Z","shell.execute_reply":"2023-11-22T15:18:19.241622Z"},"trusted":true},"execution_count":102,"outputs":[{"name":"stdout","text":"{'input_ids': [0, 39, 42, 26, 12, 18, 46, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n","output_type":"stream"}]},{"cell_type":"code","source":"example = \"Привет\"\ntokens = tokenizer.encode_plus(\n    example,\n    add_special_tokens = True,\n    max_length = 20,\n    padding = 'max_length'\n)\nprint(tokens)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:18:19.243601Z","iopub.execute_input":"2023-11-22T15:18:19.243838Z","iopub.status.idle":"2023-11-22T15:18:19.255042Z","shell.execute_reply.started":"2023-11-22T15:18:19.243816Z","shell.execute_reply":"2023-11-22T15:18:19.254226Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stdout","text":"{'input_ids': [0, 39, 42, 26, 12, 18, 46, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","output_type":"stream"}]},{"cell_type":"code","source":"#!rm -rf all_accents.zip","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:18:19.256200Z","iopub.execute_input":"2023-11-22T15:18:19.257100Z","iopub.status.idle":"2023-11-22T15:18:19.265068Z","shell.execute_reply.started":"2023-11-22T15:18:19.257065Z","shell.execute_reply":"2023-11-22T15:18:19.264321Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"!wget https://github.com/Koziev/NLP_Datasets/raw/master/Stress/all_accents.zip\n!unzip all_accents.zip","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:18:19.266306Z","iopub.execute_input":"2023-11-22T15:18:19.267041Z","iopub.status.idle":"2023-11-22T15:53:03.416408Z","shell.execute_reply.started":"2023-11-22T15:18:19.267007Z","shell.execute_reply":"2023-11-22T15:53:03.415332Z"},"trusted":true},"execution_count":105,"outputs":[{"name":"stdout","text":"--2023-11-22 15:18:20--  https://github.com/Koziev/NLP_Datasets/raw/master/Stress/all_accents.zip\nResolving github.com (github.com)... 192.30.255.112\nConnecting to github.com (github.com)|192.30.255.112|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/Koziev/NLP_Datasets/master/Stress/all_accents.zip [following]\n--2023-11-22 15:18:20--  https://raw.githubusercontent.com/Koziev/NLP_Datasets/master/Stress/all_accents.zip\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 10624775 (10M) [application/zip]\nSaving to: ‘all_accents.zip.1’\n\nall_accents.zip.1   100%[===================>]  10.13M  --.-KB/s    in 0.06s   \n\n2023-11-22 15:18:20 (163 MB/s) - ‘all_accents.zip.1’ saved [10624775/10624775]\n\nArchive:  all_accents.zip\nreplace all_accents.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfile_path = 'all_accents.tsv'\ndf = pd.read_csv(file_path, delimiter='\\t')\n\ndf.sample(20)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:12.763216Z","iopub.execute_input":"2023-11-22T15:53:12.763625Z","iopub.status.idle":"2023-11-22T15:53:15.654945Z","shell.execute_reply.started":"2023-11-22T15:53:12.763594Z","shell.execute_reply":"2023-11-22T15:53:15.654041Z"},"trusted":true},"execution_count":114,"outputs":[{"execution_count":114,"output_type":"execute_result","data":{"text/plain":"                          -де                   -д^е\n1508487              триенале              триен^але\n834827              обтиснуло             обт^иснуло\n56703          атрофирующимся        атроф^ирующимся\n276290            голубевшему           голуб^евшему\n751551            наяривающей           на^яривающей\n679202               моддингу              м^оддингу\n1590761          фунгицидному          фунгиц^идному\n139501             венчурному            в^енчурному\n72629               басовитых             басов^итых\n1014626              пленении              плен^ении\n1518237       тэрмостабильный       тэрмостаб^ильный\n1492339               тминное               тм^инное\n77195             безгрешному           безгр^ешному\n1061568       подстраховывала       подстрах^овывала\n692111   мультиплатформенными  мультиплатф^орменными\n1605794              храбрить              храбр^ить\n234637              выскочкам             в^ыскочкам\n533042            катехизация           катехиз^ация\n351797             дочурочкам            доч^урочкам\n463913              знахарями             зн^ахарями","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>-де</th>\n      <th>-д^е</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1508487</th>\n      <td>триенале</td>\n      <td>триен^але</td>\n    </tr>\n    <tr>\n      <th>834827</th>\n      <td>обтиснуло</td>\n      <td>обт^иснуло</td>\n    </tr>\n    <tr>\n      <th>56703</th>\n      <td>атрофирующимся</td>\n      <td>атроф^ирующимся</td>\n    </tr>\n    <tr>\n      <th>276290</th>\n      <td>голубевшему</td>\n      <td>голуб^евшему</td>\n    </tr>\n    <tr>\n      <th>751551</th>\n      <td>наяривающей</td>\n      <td>на^яривающей</td>\n    </tr>\n    <tr>\n      <th>679202</th>\n      <td>моддингу</td>\n      <td>м^оддингу</td>\n    </tr>\n    <tr>\n      <th>1590761</th>\n      <td>фунгицидному</td>\n      <td>фунгиц^идному</td>\n    </tr>\n    <tr>\n      <th>139501</th>\n      <td>венчурному</td>\n      <td>в^енчурному</td>\n    </tr>\n    <tr>\n      <th>72629</th>\n      <td>басовитых</td>\n      <td>басов^итых</td>\n    </tr>\n    <tr>\n      <th>1014626</th>\n      <td>пленении</td>\n      <td>плен^ении</td>\n    </tr>\n    <tr>\n      <th>1518237</th>\n      <td>тэрмостабильный</td>\n      <td>тэрмостаб^ильный</td>\n    </tr>\n    <tr>\n      <th>1492339</th>\n      <td>тминное</td>\n      <td>тм^инное</td>\n    </tr>\n    <tr>\n      <th>77195</th>\n      <td>безгрешному</td>\n      <td>безгр^ешному</td>\n    </tr>\n    <tr>\n      <th>1061568</th>\n      <td>подстраховывала</td>\n      <td>подстрах^овывала</td>\n    </tr>\n    <tr>\n      <th>692111</th>\n      <td>мультиплатформенными</td>\n      <td>мультиплатф^орменными</td>\n    </tr>\n    <tr>\n      <th>1605794</th>\n      <td>храбрить</td>\n      <td>храбр^ить</td>\n    </tr>\n    <tr>\n      <th>234637</th>\n      <td>выскочкам</td>\n      <td>в^ыскочкам</td>\n    </tr>\n    <tr>\n      <th>533042</th>\n      <td>катехизация</td>\n      <td>катехиз^ация</td>\n    </tr>\n    <tr>\n      <th>351797</th>\n      <td>дочурочкам</td>\n      <td>доч^урочкам</td>\n    </tr>\n    <tr>\n      <th>463913</th>\n      <td>знахарями</td>\n      <td>зн^ахарями</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"len(df)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:17.808945Z","iopub.execute_input":"2023-11-22T15:53:17.809335Z","iopub.status.idle":"2023-11-22T15:53:17.815468Z","shell.execute_reply.started":"2023-11-22T15:53:17.809303Z","shell.execute_reply":"2023-11-22T15:53:17.814541Z"},"trusted":true},"execution_count":115,"outputs":[{"execution_count":115,"output_type":"execute_result","data":{"text/plain":"1680534"},"metadata":{}}]},{"cell_type":"code","source":"max_length = df['-де'].apply(len).max()\n\nlongest_string = df[df['-де'].apply(len) == max_length]['-де'].values[0]\n\nprint(\"Самая длинная строка:\", longest_string)\nprint(\"Длина строки:\", max_length)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:18.553829Z","iopub.execute_input":"2023-11-22T15:53:18.554176Z","iopub.status.idle":"2023-11-22T15:53:20.145446Z","shell.execute_reply.started":"2023-11-22T15:53:18.554146Z","shell.execute_reply":"2023-11-22T15:53:20.144391Z"},"trusted":true},"execution_count":116,"outputs":[{"name":"stdout","text":"Самая длинная строка: лланвайрпуллгуингиллгогерихуирндробуллллантисилиогогогох\nДлина строки: 56\n","output_type":"stream"}]},{"cell_type":"code","source":"df.iloc[624999]","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:20.146950Z","iopub.execute_input":"2023-11-22T15:53:20.147217Z","iopub.status.idle":"2023-11-22T15:53:20.153996Z","shell.execute_reply.started":"2023-11-22T15:53:20.147194Z","shell.execute_reply":"2023-11-22T15:53:20.153131Z"},"trusted":true},"execution_count":117,"outputs":[{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"-де     лланвайрпуллгуингиллгогерихуирндробуллллантиси...\n-д^е    лланвайрпуллгуингиллгогерихуирндробуллллантиси...\nName: 624999, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"*Жесткач :)*","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:21.095200Z","iopub.execute_input":"2023-11-22T15:53:21.095565Z","iopub.status.idle":"2023-11-22T15:53:21.099994Z","shell.execute_reply.started":"2023-11-22T15:53:21.095537Z","shell.execute_reply":"2023-11-22T15:53:21.099003Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:21.794732Z","iopub.execute_input":"2023-11-22T15:53:21.795586Z","iopub.status.idle":"2023-11-22T15:53:21.800011Z","shell.execute_reply.started":"2023-11-22T15:53:21.795544Z","shell.execute_reply":"2023-11-22T15:53:21.799014Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"class StressDataset(Dataset):\n    def __init__(self, file_path, max_length=56, test_size=0.5, random_seed=42):\n        self.df = pd.read_csv(file_path, delimiter='\\t')\n        self.chars = \"АаБбВвГгДдЕеЁёЖжЗзИиЙйКкЛлМмНнОоПпРрСсТтУуФфХхЦцЧчШшЩщЪъЫыЬьЭэЮюЯя\"\n        self.model_max_length = 64\n        self.tokenizer = CharacterTokenizer(self.chars, self.model_max_length)\n        self.word_max_length = max_length\n\n        self.train_data_index, self.test_data_index = (\n            train_test_split(\n                self.df.index,\n                test_size=test_size,\n                random_state=random_seed\n            )\n        )\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        text = self.df.loc[idx, '-де']\n        label = self.df.loc[idx, '-д^е']\n\n        tokens = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.word_max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        # [CLS]востфак[SEP][PAD]...[PAD]\n        # востфак востф^ак\n        number_stress_token = label.find('^') + 1\n        labels = [0]*len(tokens['attention_mask'].squeeze())\n        labels[number_stress_token] = 1\n        \n        labels = torch.tensor(labels, dtype=torch.long)\n        tokens['labels'] = labels\n        return tokens\n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:22.458891Z","iopub.execute_input":"2023-11-22T15:53:22.459225Z","iopub.status.idle":"2023-11-22T15:53:22.469643Z","shell.execute_reply.started":"2023-11-22T15:53:22.459196Z","shell.execute_reply":"2023-11-22T15:53:22.468688Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"file_path = 'all_accents.tsv'\nstress_dataset = StressDataset(file_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:23.417632Z","iopub.execute_input":"2023-11-22T15:53:23.418407Z","iopub.status.idle":"2023-11-22T15:53:26.286318Z","shell.execute_reply.started":"2023-11-22T15:53:23.418372Z","shell.execute_reply":"2023-11-22T15:53:26.285498Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"INDEX = 107500\nword_tokens = stress_dataset[INDEX]\n(\nword_tokens['labels'],\ndf.iloc[INDEX].values[0],\ndf.iloc[INDEX].values[1],\ntokenizer.decode(word_tokens['input_ids'].squeeze().tolist())\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:26.287828Z","iopub.execute_input":"2023-11-22T15:53:26.288127Z","iopub.status.idle":"2023-11-22T15:53:26.299127Z","shell.execute_reply.started":"2023-11-22T15:53:26.288101Z","shell.execute_reply":"2023-11-22T15:53:26.298234Z"},"trusted":true},"execution_count":122,"outputs":[{"execution_count":122,"output_type":"execute_result","data":{"text/plain":"(tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]),\n 'бордель',\n 'борд^ель',\n '[CLS]бордель[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]')"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import Subset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:26.300291Z","iopub.execute_input":"2023-11-22T15:53:26.300884Z","iopub.status.idle":"2023-11-22T15:53:26.307020Z","shell.execute_reply.started":"2023-11-22T15:53:26.300857Z","shell.execute_reply":"2023-11-22T15:53:26.306129Z"},"trusted":true},"execution_count":123,"outputs":[]},{"cell_type":"code","source":"file_path = 'all_accents.tsv'\nstress_dataset = StressDataset(file_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:26.905309Z","iopub.execute_input":"2023-11-22T15:53:26.906187Z","iopub.status.idle":"2023-11-22T15:53:29.940719Z","shell.execute_reply.started":"2023-11-22T15:53:26.906151Z","shell.execute_reply":"2023-11-22T15:53:29.939794Z"},"trusted":true},"execution_count":124,"outputs":[]},{"cell_type":"code","source":"def collate_fn(batch):\n    input_ids = torch.stack([sample['input_ids'] for sample in batch])\n    attention_mask = torch.stack([sample['attention_mask'] for sample in batch])\n    labels = torch.stack([sample['labels'] for sample in batch])\n\n    return [input_ids.squeeze(1), attention_mask.squeeze(1), labels]\n\nbatch_size = 256\n\ntrain_loader = DataLoader(\n    Subset(stress_dataset, stress_dataset.train_data_index),\n    batch_size=batch_size,\n    shuffle=True,\n    drop_last = True,\n    collate_fn = collate_fn,\n)\n\ntest_loader = DataLoader(\n    Subset(stress_dataset, stress_dataset.test_data_index),\n    batch_size=batch_size,\n    shuffle=False,\n    collate_fn = collate_fn,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:29.942634Z","iopub.execute_input":"2023-11-22T15:53:29.943327Z","iopub.status.idle":"2023-11-22T15:53:30.178442Z","shell.execute_reply.started":"2023-11-22T15:53:29.943288Z","shell.execute_reply":"2023-11-22T15:53:30.177230Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n\n    # Tell PyTorch to use the GPU.\n    device = torch.device(\"cuda\")\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n\n# If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:30.179731Z","iopub.execute_input":"2023-11-22T15:53:30.180018Z","iopub.status.idle":"2023-11-22T15:53:30.195093Z","shell.execute_reply.started":"2023-11-22T15:53:30.179991Z","shell.execute_reply":"2023-11-22T15:53:30.194132Z"},"trusted":true},"execution_count":126,"outputs":[{"name":"stdout","text":"There are 1 GPU(s) available.\nWe will use the GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers\n!pip install pynvml","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:30.197325Z","iopub.execute_input":"2023-11-22T15:53:30.198007Z","iopub.status.idle":"2023-11-22T15:53:53.258947Z","shell.execute_reply.started":"2023-11-22T15:53:30.197958Z","shell.execute_reply":"2023-11-22T15:53:53.257724Z"},"trusted":true},"execution_count":127,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nRequirement already satisfied: pynvml in /opt/conda/lib/python3.10/site-packages (11.4.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"#TEST\ncnt = 0\nfor batch in train_loader:\n    print(len(batch[0]), len(batch[1]), len(batch[2]))\n    print(type(batch[0]), type(batch[1]), type(batch[2]))\n    cnt += 1\n    if cnt == 3:\n        break","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:53.260473Z","iopub.execute_input":"2023-11-22T15:53:53.260770Z","iopub.status.idle":"2023-11-22T15:53:53.541402Z","shell.execute_reply.started":"2023-11-22T15:53:53.260743Z","shell.execute_reply":"2023-11-22T15:53:53.540317Z"},"trusted":true},"execution_count":128,"outputs":[{"name":"stdout","text":"256 256 256\n<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n256 256 256\n<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n256 256 256\n<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n","output_type":"stream"}]},{"cell_type":"code","source":"#TEST\nfor batch in train_loader:\n    print(batch[0].shape, batch[1].shape, batch[2].shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:53.697308Z","iopub.execute_input":"2023-11-22T15:53:53.697582Z","iopub.status.idle":"2023-11-22T15:53:53.840159Z","shell.execute_reply.started":"2023-11-22T15:53:53.697556Z","shell.execute_reply":"2023-11-22T15:53:53.839136Z"},"trusted":true},"execution_count":131,"outputs":[{"name":"stdout","text":"torch.Size([256, 56]) torch.Size([256, 56]) torch.Size([256, 56])\n","output_type":"stream"}]},{"cell_type":"code","source":"from pynvml import *\n\n\ndef print_gpu_utilization():\n    nvmlInit()\n    handle = nvmlDeviceGetHandleByIndex(0)\n    info = nvmlDeviceGetMemoryInfo(handle)\n    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:53.849372Z","iopub.execute_input":"2023-11-22T15:53:53.849970Z","iopub.status.idle":"2023-11-22T15:53:53.859686Z","shell.execute_reply.started":"2023-11-22T15:53:53.849933Z","shell.execute_reply":"2023-11-22T15:53:53.858799Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom transformers import BertForTokenClassification, AdamW\n\nfrom transformers import BertConfig\n\nconfig = BertConfig(\n    hidden_size=512,\n    num_labels=2,  # 2 класса: \"NO\", \"PRIMARY\"\n    output_attentions=False,\n    output_hidden_states=False,\n    num_attention_heads=8,\n    num_hidden_layers=4,\n    max_position_embeddings=60,\n    pad_token_id=0,\n    id2label={\n        \"0\": \"NO\",\n        \"1\": \"PRIMARY\",\n    },\n    label2id={\n        \"NO\": 0,\n        \"PRIMARY\": 1,\n    },\n)\n\nmodel = BertForTokenClassification(config)\nmodel.cuda()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:53.863314Z","iopub.execute_input":"2023-11-22T15:53:53.863732Z","iopub.status.idle":"2023-11-22T15:53:54.390342Z","shell.execute_reply.started":"2023-11-22T15:53:53.863698Z","shell.execute_reply":"2023-11-22T15:53:54.389409Z"},"trusted":true},"execution_count":134,"outputs":[{"execution_count":134,"output_type":"execute_result","data":{"text/plain":"BertForTokenClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 512, padding_idx=0)\n      (position_embeddings): Embedding(60, 512)\n      (token_type_embeddings): Embedding(2, 512)\n      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-3): 4 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=512, out_features=512, bias=True)\n              (key): Linear(in_features=512, out_features=512, bias=True)\n              (value): Linear(in_features=512, out_features=512, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=512, out_features=512, bias=True)\n              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=512, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=512, bias=True)\n            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=512, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import get_linear_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:54.391565Z","iopub.execute_input":"2023-11-22T15:53:54.391857Z","iopub.status.idle":"2023-11-22T15:53:54.396116Z","shell.execute_reply.started":"2023-11-22T15:53:54.391831Z","shell.execute_reply":"2023-11-22T15:53:54.395077Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\nepochs = 1\n\ntotal_steps = len(train_loader) * epochs\n\nscheduler = get_linear_schedule_with_warmup(optimizer,\n                                            num_warmup_steps = 0,\n                                            num_training_steps = total_steps)\ncriterion = torch.nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:54.397485Z","iopub.execute_input":"2023-11-22T15:53:54.397832Z","iopub.status.idle":"2023-11-22T15:53:54.413340Z","shell.execute_reply.started":"2023-11-22T15:53:54.397798Z","shell.execute_reply":"2023-11-22T15:53:54.412437Z"},"trusted":true},"execution_count":136,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Function to calculate the accuracy of our predictions vs labels\ndef flat_accuracy(preds, labels):\n    pred_labels_flat = np.argmax(preds, axis=-1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_labels_flat == labels_flat) / len(labels_flat)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:54.414794Z","iopub.execute_input":"2023-11-22T15:53:54.415854Z","iopub.status.idle":"2023-11-22T15:53:54.421844Z","shell.execute_reply.started":"2023-11-22T15:53:54.415818Z","shell.execute_reply":"2023-11-22T15:53:54.420819Z"},"trusted":true},"execution_count":137,"outputs":[]},{"cell_type":"code","source":"# TEST\n#for batch in train_loader:\n#    with torch.no_grad():\n#        output = model(\n#            batch[0].to(device),\n#            token_type_ids=None,\n#            attention_mask=batch[1].to(device),\n#            labels=batch[2].to(device)\n#        )\n#    \n#    logits = output.logits.detach().cpu().numpy()\n#    label_ids = batch[2].to('cpu').numpy()\n#    break\n#","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:54.422974Z","iopub.execute_input":"2023-11-22T15:53:54.423253Z","iopub.status.idle":"2023-11-22T15:53:54.432289Z","shell.execute_reply.started":"2023-11-22T15:53:54.423217Z","shell.execute_reply":"2023-11-22T15:53:54.431341Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"#logits.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-22T13:34:28.662324Z","iopub.execute_input":"2023-11-22T13:34:28.663135Z","iopub.status.idle":"2023-11-22T13:34:28.669081Z","shell.execute_reply.started":"2023-11-22T13:34:28.663100Z","shell.execute_reply":"2023-11-22T13:34:28.668172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#label_ids.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-22T13:32:56.093179Z","iopub.execute_input":"2023-11-22T13:32:56.093592Z","iopub.status.idle":"2023-11-22T13:32:56.099716Z","shell.execute_reply.started":"2023-11-22T13:32:56.093557Z","shell.execute_reply":"2023-11-22T13:32:56.098795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#np.argmax(logits, axis=-1)[0], label_ids[0]\n","metadata":{"execution":{"iopub.status.busy":"2023-11-22T13:35:51.985250Z","iopub.execute_input":"2023-11-22T13:35:51.986204Z","iopub.status.idle":"2023-11-22T13:35:51.993456Z","shell.execute_reply.started":"2023-11-22T13:35:51.986169Z","shell.execute_reply":"2023-11-22T13:35:51.992510Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport datetime\n\ndef format_time(elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n\n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:54.433435Z","iopub.execute_input":"2023-11-22T15:53:54.433757Z","iopub.status.idle":"2023-11-22T15:53:54.442102Z","shell.execute_reply.started":"2023-11-22T15:53:54.433725Z","shell.execute_reply":"2023-11-22T15:53:54.441316Z"},"trusted":true},"execution_count":139,"outputs":[]},{"cell_type":"markdown","source":"## пайплайн обучения","metadata":{}},{"cell_type":"code","source":"import random\nimport numpy as np\n\n# Set the seed value all over the place to make this reproducible.\nseed_val = 42\n\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\n\n\ntraining_stats = []\n\n\ntotal_t0 = time.time()\n\nfor epoch_i in range(0, epochs):\n\n    print(\"\")\n    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n    print('Training...')\n    t0 = time.time()\n\n    total_train_loss = 0\n    total_train_accuracy = 0\n    \n    model.train()\n\n    for step, batch in enumerate(train_loader):\n        # Progress update every 100 batches.\n        if step % 100 == 0 and not step == 0:\n            # Calculate elapsed time in minutes.\n            elapsed = format_time(time.time() - t0)\n\n            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_loader), elapsed))\n\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        model.zero_grad()\n        output = model(\n            b_input_ids,\n            token_type_ids=None,\n            attention_mask=b_input_mask,\n            labels=b_labels,\n            return_dict=True\n        )\n\n        total_train_loss += output.loss.item()\n\n        output.loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n        \n        logits = output.logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n\n\n        total_train_accuracy += flat_accuracy(logits, label_ids)\n\n\n    avg_train_accuracy = total_train_accuracy / len(train_loader)\n\n    avg_train_loss = total_train_loss / len(train_loader)\n\n    training_time = format_time(time.time() - t0)\n\n    print(\"\")\n    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n    print(\"  Accuracy: {0:.2f}\".format(avg_train_accuracy))\n    print(\"  Training epoch took: {:}\".format(training_time))\n\n    # ========================================\n    #               Validation\n    # ========================================\n\n    print(\"\")\n    print(\"Running Validation...\")\n\n    t0 = time.time()\n\n\n    model.eval()\n\n    # Tracking variables\n    total_eval_accuracy = 0\n    total_eval_loss = 0\n    nb_eval_steps = 0\n\n    # Evaluate data for one epoch\n    for batch in test_loader:\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n\n        with torch.no_grad():\n\n\n            output = model(b_input_ids,\n                                   token_type_ids=None,\n                                   attention_mask=b_input_mask,\n                                   labels=b_labels)\n\n        # Accumulate the validation loss.\n        total_eval_loss += output.loss.item()\n\n        # Move logits and labels to CPU\n        logits = output.logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n\n\n        total_eval_accuracy += flat_accuracy(logits, label_ids)\n\n\n    avg_val_accuracy = total_eval_accuracy / len(test_loader)\n    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n\n    # Calculate the average loss over all of the batches.\n    avg_val_loss = total_eval_loss / len(test_loader)\n\n    # Measure how long the validation run took.\n    validation_time = format_time(time.time() - t0)\n\n    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n    print(\"  Validation took: {:}\".format(validation_time))\n\n    # Record all statistics from this epoch.\n    training_stats.append(\n        {\n            'epoch': epoch_i + 1,\n            'Training Loss': avg_train_loss,\n            'Valid. Loss': avg_val_loss,\n            'Valid. Accur.': avg_val_accuracy,\n            'Training Time': training_time,\n            'Validation Time': validation_time\n        }\n    )\n\nprint(\"\")\nprint(\"Training complete!\")\n\nprint(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:54.443525Z","iopub.execute_input":"2023-11-22T15:53:54.444255Z","iopub.status.idle":"2023-11-22T16:18:29.373391Z","shell.execute_reply.started":"2023-11-22T15:53:54.444222Z","shell.execute_reply":"2023-11-22T16:18:29.372328Z"},"trusted":true},"execution_count":140,"outputs":[{"name":"stdout","text":"\n======== Epoch 1 / 1 ========\nTraining...\n  Batch   100  of  3,282.    Elapsed: 0:00:31.\n  Batch   200  of  3,282.    Elapsed: 0:01:01.\n  Batch   300  of  3,282.    Elapsed: 0:01:31.\n  Batch   400  of  3,282.    Elapsed: 0:02:01.\n  Batch   500  of  3,282.    Elapsed: 0:02:31.\n  Batch   600  of  3,282.    Elapsed: 0:03:01.\n  Batch   700  of  3,282.    Elapsed: 0:03:31.\n  Batch   800  of  3,282.    Elapsed: 0:04:01.\n  Batch   900  of  3,282.    Elapsed: 0:04:31.\n  Batch 1,000  of  3,282.    Elapsed: 0:05:01.\n  Batch 1,100  of  3,282.    Elapsed: 0:05:31.\n  Batch 1,200  of  3,282.    Elapsed: 0:06:01.\n  Batch 1,300  of  3,282.    Elapsed: 0:06:31.\n  Batch 1,400  of  3,282.    Elapsed: 0:07:01.\n  Batch 1,500  of  3,282.    Elapsed: 0:07:31.\n  Batch 1,600  of  3,282.    Elapsed: 0:08:02.\n  Batch 1,700  of  3,282.    Elapsed: 0:08:31.\n  Batch 1,800  of  3,282.    Elapsed: 0:09:02.\n  Batch 1,900  of  3,282.    Elapsed: 0:09:32.\n  Batch 2,000  of  3,282.    Elapsed: 0:10:02.\n  Batch 2,100  of  3,282.    Elapsed: 0:10:32.\n  Batch 2,200  of  3,282.    Elapsed: 0:11:02.\n  Batch 2,300  of  3,282.    Elapsed: 0:11:33.\n  Batch 2,400  of  3,282.    Elapsed: 0:12:03.\n  Batch 2,500  of  3,282.    Elapsed: 0:12:33.\n  Batch 2,600  of  3,282.    Elapsed: 0:13:03.\n  Batch 2,700  of  3,282.    Elapsed: 0:13:33.\n  Batch 2,800  of  3,282.    Elapsed: 0:14:03.\n  Batch 2,900  of  3,282.    Elapsed: 0:14:34.\n  Batch 3,000  of  3,282.    Elapsed: 0:15:05.\n  Batch 3,100  of  3,282.    Elapsed: 0:15:35.\n  Batch 3,200  of  3,282.    Elapsed: 0:16:05.\n\n  Average training loss: 0.03\n  Accuracy: 0.99\n  Training epoch took: 0:16:30\n\nRunning Validation...\n  Accuracy: 0.99\n  Validation Loss: 0.02\n  Validation took: 0:08:05\n\nTraining complete!\nTotal training took 0:24:35 (h:mm:ss)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Accuracy: 0.99","metadata":{}}]}