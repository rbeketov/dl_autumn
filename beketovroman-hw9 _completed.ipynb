{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/KuzmaKhrabrov/character-tokenizer.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-23T07:32:30.444510Z","iopub.execute_input":"2023-11-23T07:32:30.444822Z","iopub.status.idle":"2023-11-23T07:32:32.108030Z","shell.execute_reply.started":"2023-11-23T07:32:30.444767Z","shell.execute_reply":"2023-11-23T07:32:32.106767Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Cloning into 'character-tokenizer'...\nremote: Enumerating objects: 20, done.\u001b[K\nremote: Counting objects: 100% (20/20), done.\u001b[K\nremote: Compressing objects: 100% (14/14), done.\u001b[K\nremote: Total 20 (delta 5), reused 10 (delta 3), pack-reused 0\u001b[K\nReceiving objects: 100% (20/20), 5.89 KiB | 1.96 MiB/s, done.\nResolving deltas: 100% (5/5), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:32:37.625925Z","iopub.execute_input":"2023-11-23T07:32:37.626904Z","iopub.status.idle":"2023-11-23T07:32:50.308266Z","shell.execute_reply.started":"2023-11-23T07:32:37.626865Z","shell.execute_reply":"2023-11-23T07:32:50.307137Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n","output_type":"stream"}]},{"cell_type":"code","source":"import string\nimport sys\nsys.path.append(\"character-tokenizer\")\nfrom charactertokenizer import CharacterTokenizer\n\nchars = \"АаБбВвГгДдЕеЁёЖжЗзИиЙйКкЛлМмНнОоПпРрСсТтУуФфХхЦцЧчШшЩщЪъЫыЬьЭэЮюЯя\"\nmodel_max_length = 64\ntokenizer = CharacterTokenizer(chars, model_max_length)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:33:16.446057Z","iopub.execute_input":"2023-11-23T07:33:16.446447Z","iopub.status.idle":"2023-11-23T07:33:21.033708Z","shell.execute_reply.started":"2023-11-23T07:33:16.446415Z","shell.execute_reply":"2023-11-23T07:33:21.032909Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"len(chars)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:33:21.035268Z","iopub.execute_input":"2023-11-23T07:33:21.036102Z","iopub.status.idle":"2023-11-23T07:33:21.042743Z","shell.execute_reply.started":"2023-11-23T07:33:21.036064Z","shell.execute_reply":"2023-11-23T07:33:21.041918Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"66"},"metadata":{}}]},{"cell_type":"code","source":"example = \"Привет\"\ntokens = tokenizer(example)\nprint(tokens)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:33:23.035083Z","iopub.execute_input":"2023-11-23T07:33:23.035835Z","iopub.status.idle":"2023-11-23T07:33:23.040573Z","shell.execute_reply.started":"2023-11-23T07:33:23.035796Z","shell.execute_reply":"2023-11-23T07:33:23.039680Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"{'input_ids': [0, 39, 42, 26, 12, 18, 46, 1], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}\n","output_type":"stream"}]},{"cell_type":"code","source":"example = \"Привет\"\ntokens = tokenizer.encode_plus(\n    example,\n    add_special_tokens = True,\n    max_length = 20,\n    padding = 'max_length'\n)\nprint(tokens)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:33:25.079649Z","iopub.execute_input":"2023-11-23T07:33:25.080018Z","iopub.status.idle":"2023-11-23T07:33:25.085557Z","shell.execute_reply.started":"2023-11-23T07:33:25.079989Z","shell.execute_reply":"2023-11-23T07:33:25.084747Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"{'input_ids': [0, 39, 42, 26, 12, 18, 46, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n","output_type":"stream"}]},{"cell_type":"code","source":"#!rm -rf all_accents.zip","metadata":{"execution":{"iopub.status.busy":"2023-11-22T19:50:10.082267Z","iopub.execute_input":"2023-11-22T19:50:10.082530Z","iopub.status.idle":"2023-11-22T19:50:10.092352Z","shell.execute_reply.started":"2023-11-22T19:50:10.082506Z","shell.execute_reply":"2023-11-22T19:50:10.091486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://github.com/Koziev/NLP_Datasets/raw/master/Stress/all_accents.zip\n!unzip all_accents.zip","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:33:28.873594Z","iopub.execute_input":"2023-11-23T07:33:28.873983Z","iopub.status.idle":"2023-11-23T07:33:32.008950Z","shell.execute_reply.started":"2023-11-23T07:33:28.873951Z","shell.execute_reply":"2023-11-23T07:33:32.007917Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"--2023-11-23 07:33:29--  https://github.com/Koziev/NLP_Datasets/raw/master/Stress/all_accents.zip\nResolving github.com (github.com)... 140.82.121.3\nConnecting to github.com (github.com)|140.82.121.3|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/Koziev/NLP_Datasets/master/Stress/all_accents.zip [following]\n--2023-11-23 07:33:29--  https://raw.githubusercontent.com/Koziev/NLP_Datasets/master/Stress/all_accents.zip\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 10624775 (10M) [application/zip]\nSaving to: ‘all_accents.zip’\n\nall_accents.zip     100%[===================>]  10.13M  --.-KB/s    in 0.05s   \n\n2023-11-23 07:33:30 (193 MB/s) - ‘all_accents.zip’ saved [10624775/10624775]\n\nArchive:  all_accents.zip\n  inflating: all_accents.tsv         \n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfile_path = 'all_accents.tsv'\ndf = pd.read_csv(file_path, delimiter='\\t')\n\ndf.sample(20)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:33:33.268767Z","iopub.execute_input":"2023-11-23T07:33:33.269143Z","iopub.status.idle":"2023-11-23T07:33:36.786982Z","shell.execute_reply.started":"2023-11-23T07:33:33.269112Z","shell.execute_reply":"2023-11-23T07:33:36.785944Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                       -де                -д^е\n881120          осеняющего         осен^яющего\n775361    непридыхательное   непридых^ательное\n368921            жалобных           ж^алобных\n1128677       пошатываниях       пош^атываниях\n1525112        увильнувшем        увильн^увшем\n1010138      питбультэрьер      питбультэрь^ер\n1474477         тактильных         такт^ильных\n1494800          томашевич          том^ашевич\n108606           боронится          борон^ится\n951043        пассажирском       пассаж^ирском\n1369310   семнадцатилетних   семнадцатил^етних\n1347969            сарабуз            сар^абуз\n1576916           фигачила           фиг^ачила\n115561       брутальнейший      брут^альнейший\n312317            дернулся           д^ернулся\n141679          вертлужный         вертл^ужный\n330283      договорившаяся     договор^ившаяся\n849599   односеменодольней  односеменод^ольней\n229627        выпучивалось       вып^учивалось\n796339          носачевичи         носач^евичи","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>-де</th>\n      <th>-д^е</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>881120</th>\n      <td>осеняющего</td>\n      <td>осен^яющего</td>\n    </tr>\n    <tr>\n      <th>775361</th>\n      <td>непридыхательное</td>\n      <td>непридых^ательное</td>\n    </tr>\n    <tr>\n      <th>368921</th>\n      <td>жалобных</td>\n      <td>ж^алобных</td>\n    </tr>\n    <tr>\n      <th>1128677</th>\n      <td>пошатываниях</td>\n      <td>пош^атываниях</td>\n    </tr>\n    <tr>\n      <th>1525112</th>\n      <td>увильнувшем</td>\n      <td>увильн^увшем</td>\n    </tr>\n    <tr>\n      <th>1010138</th>\n      <td>питбультэрьер</td>\n      <td>питбультэрь^ер</td>\n    </tr>\n    <tr>\n      <th>1474477</th>\n      <td>тактильных</td>\n      <td>такт^ильных</td>\n    </tr>\n    <tr>\n      <th>1494800</th>\n      <td>томашевич</td>\n      <td>том^ашевич</td>\n    </tr>\n    <tr>\n      <th>108606</th>\n      <td>боронится</td>\n      <td>борон^ится</td>\n    </tr>\n    <tr>\n      <th>951043</th>\n      <td>пассажирском</td>\n      <td>пассаж^ирском</td>\n    </tr>\n    <tr>\n      <th>1369310</th>\n      <td>семнадцатилетних</td>\n      <td>семнадцатил^етних</td>\n    </tr>\n    <tr>\n      <th>1347969</th>\n      <td>сарабуз</td>\n      <td>сар^абуз</td>\n    </tr>\n    <tr>\n      <th>1576916</th>\n      <td>фигачила</td>\n      <td>фиг^ачила</td>\n    </tr>\n    <tr>\n      <th>115561</th>\n      <td>брутальнейший</td>\n      <td>брут^альнейший</td>\n    </tr>\n    <tr>\n      <th>312317</th>\n      <td>дернулся</td>\n      <td>д^ернулся</td>\n    </tr>\n    <tr>\n      <th>141679</th>\n      <td>вертлужный</td>\n      <td>вертл^ужный</td>\n    </tr>\n    <tr>\n      <th>330283</th>\n      <td>договорившаяся</td>\n      <td>договор^ившаяся</td>\n    </tr>\n    <tr>\n      <th>849599</th>\n      <td>односеменодольней</td>\n      <td>односеменод^ольней</td>\n    </tr>\n    <tr>\n      <th>229627</th>\n      <td>выпучивалось</td>\n      <td>вып^учивалось</td>\n    </tr>\n    <tr>\n      <th>796339</th>\n      <td>носачевичи</td>\n      <td>носач^евичи</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"len(df)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:33:36.927939Z","iopub.execute_input":"2023-11-23T07:33:36.928567Z","iopub.status.idle":"2023-11-23T07:33:36.934261Z","shell.execute_reply.started":"2023-11-23T07:33:36.928535Z","shell.execute_reply":"2023-11-23T07:33:36.933273Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"1680534"},"metadata":{}}]},{"cell_type":"code","source":"max_length = df['-де'].apply(len).max()\n\nlongest_string = df[df['-де'].apply(len) == max_length]['-де'].values[0]\n\nprint(\"Самая длинная строка:\", longest_string)\nprint(\"Длина строки:\", max_length)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:33:40.271473Z","iopub.execute_input":"2023-11-23T07:33:40.272320Z","iopub.status.idle":"2023-11-23T07:33:41.874096Z","shell.execute_reply.started":"2023-11-23T07:33:40.272286Z","shell.execute_reply":"2023-11-23T07:33:41.873057Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Самая длинная строка: лланвайрпуллгуингиллгогерихуирндробуллллантисилиогогогох\nДлина строки: 56\n","output_type":"stream"}]},{"cell_type":"code","source":"df.iloc[624999]","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:33:43.540993Z","iopub.execute_input":"2023-11-23T07:33:43.541716Z","iopub.status.idle":"2023-11-23T07:33:43.548525Z","shell.execute_reply.started":"2023-11-23T07:33:43.541685Z","shell.execute_reply":"2023-11-23T07:33:43.547544Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"-де     лланвайрпуллгуингиллгогерихуирндробуллллантиси...\n-д^е    лланвайрпуллгуингиллгогерихуирндробуллллантиси...\nName: 624999, dtype: object"},"metadata":{}}]},{"cell_type":"markdown","source":"*Жесткач :)*","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:33:45.616394Z","iopub.execute_input":"2023-11-23T07:33:45.617247Z","iopub.status.idle":"2023-11-23T07:33:45.621177Z","shell.execute_reply.started":"2023-11-23T07:33:45.617214Z","shell.execute_reply":"2023-11-23T07:33:45.620200Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:33:47.412867Z","iopub.execute_input":"2023-11-23T07:33:47.413221Z","iopub.status.idle":"2023-11-23T07:33:47.880741Z","shell.execute_reply.started":"2023-11-23T07:33:47.413191Z","shell.execute_reply":"2023-11-23T07:33:47.879965Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"class StressDataset(Dataset):\n    def __init__(self, file_path, max_length=56, test_size=0.5, random_seed=42):\n        self.df = pd.read_csv(file_path, delimiter='\\t')\n        self.chars = \"АаБбВвГгДдЕеЁёЖжЗзИиЙйКкЛлМмНнОоПпРрСсТтУуФфХхЦцЧчШшЩщЪъЫыЬьЭэЮюЯя\"\n        self.model_max_length = 64\n        self.tokenizer = CharacterTokenizer(self.chars, self.model_max_length)\n        self.word_max_length = max_length\n\n        self.train_data_index, self.test_data_index = (\n            train_test_split(\n                self.df.index,\n                test_size=test_size,\n                random_state=random_seed\n            )\n        )\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        text = self.df.loc[idx, '-де']\n        label = self.df.loc[idx, '-д^е']\n\n        tokens = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.word_max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        # [CLS]востфак[SEP][PAD]...[PAD]\n        # востфак востф^ак\n        number_stress_token = label.find('^') + 1\n        labels = [0]*len(tokens['attention_mask'].squeeze())\n        labels[number_stress_token] = 1\n        \n        labels = torch.tensor(labels, dtype=torch.long)\n        tokens['labels'] = labels\n        return tokens\n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:33:49.595680Z","iopub.execute_input":"2023-11-23T07:33:49.596538Z","iopub.status.idle":"2023-11-23T07:33:49.606211Z","shell.execute_reply.started":"2023-11-23T07:33:49.596502Z","shell.execute_reply":"2023-11-23T07:33:49.605301Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"file_path = 'all_accents.tsv'\nstress_dataset = StressDataset(file_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:33:52.615156Z","iopub.execute_input":"2023-11-23T07:33:52.615932Z","iopub.status.idle":"2023-11-23T07:33:55.603841Z","shell.execute_reply.started":"2023-11-23T07:33:52.615899Z","shell.execute_reply":"2023-11-23T07:33:55.603024Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"INDEX = 107500\nword_tokens = stress_dataset[INDEX]\n(\nword_tokens['labels'],\ndf.iloc[INDEX].values[0],\ndf.iloc[INDEX].values[1],\ntokenizer.decode(word_tokens['input_ids'].squeeze().tolist())\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:33:56.200014Z","iopub.execute_input":"2023-11-23T07:33:56.200662Z","iopub.status.idle":"2023-11-23T07:34:06.363576Z","shell.execute_reply.started":"2023-11-23T07:33:56.200629Z","shell.execute_reply":"2023-11-23T07:34:06.362704Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0]),\n 'бордель',\n 'борд^ель',\n '[CLS]бордель[SEP][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]')"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import Subset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:34:06.365178Z","iopub.execute_input":"2023-11-23T07:34:06.365686Z","iopub.status.idle":"2023-11-23T07:34:06.370211Z","shell.execute_reply.started":"2023-11-23T07:34:06.365659Z","shell.execute_reply":"2023-11-23T07:34:06.369372Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"file_path = 'all_accents.tsv'\nstress_dataset = StressDataset(file_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:34:06.371599Z","iopub.execute_input":"2023-11-23T07:34:06.371953Z","iopub.status.idle":"2023-11-23T07:34:09.470576Z","shell.execute_reply.started":"2023-11-23T07:34:06.371920Z","shell.execute_reply":"2023-11-23T07:34:09.469797Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def collate_fn(batch):\n    input_ids = torch.stack([sample['input_ids'] for sample in batch])\n    attention_mask = torch.stack([sample['attention_mask'] for sample in batch])\n    labels = torch.stack([sample['labels'] for sample in batch])\n\n    return [input_ids.squeeze(1), attention_mask.squeeze(1), labels]\n\nbatch_size = 256\n\ntrain_loader = DataLoader(\n    Subset(stress_dataset, stress_dataset.train_data_index),\n    batch_size=batch_size,\n    shuffle=True,\n    drop_last = True,\n    collate_fn = collate_fn,\n)\n\ntest_loader = DataLoader(\n    Subset(stress_dataset, stress_dataset.test_data_index),\n    batch_size=batch_size,\n    shuffle=False,\n    collate_fn = collate_fn,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:34:09.473410Z","iopub.execute_input":"2023-11-23T07:34:09.473787Z","iopub.status.idle":"2023-11-23T07:34:09.481303Z","shell.execute_reply.started":"2023-11-23T07:34:09.473737Z","shell.execute_reply":"2023-11-23T07:34:09.480342Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n\n    # Tell PyTorch to use the GPU.\n    device = torch.device(\"cuda\")\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n\n# If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-11-23T08:07:53.349631Z","iopub.execute_input":"2023-11-23T08:07:53.350517Z","iopub.status.idle":"2023-11-23T08:07:53.356463Z","shell.execute_reply.started":"2023-11-23T08:07:53.350482Z","shell.execute_reply":"2023-11-23T08:07:53.355544Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"There are 1 GPU(s) available.\nWe will use the GPU: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers\n!pip install pynvml","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:34:09.541943Z","iopub.execute_input":"2023-11-23T07:34:09.542238Z","iopub.status.idle":"2023-11-23T07:34:32.573993Z","shell.execute_reply.started":"2023-11-23T07:34:09.542211Z","shell.execute_reply":"2023-11-23T07:34:32.572732Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.35.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nRequirement already satisfied: pynvml in /opt/conda/lib/python3.10/site-packages (11.4.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"#TEST\ncnt = 0\nfor batch in train_loader:\n    print(len(batch[0]), len(batch[1]), len(batch[2]))\n    print(type(batch[0]), type(batch[1]), type(batch[2]))\n    cnt += 1\n    if cnt == 3:\n        break","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:34:32.575801Z","iopub.execute_input":"2023-11-23T07:34:32.576693Z","iopub.status.idle":"2023-11-23T07:34:32.905582Z","shell.execute_reply.started":"2023-11-23T07:34:32.576653Z","shell.execute_reply":"2023-11-23T07:34:32.904540Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"256 256 256\n<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n256 256 256\n<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n256 256 256\n<class 'torch.Tensor'> <class 'torch.Tensor'> <class 'torch.Tensor'>\n","output_type":"stream"}]},{"cell_type":"code","source":"#TEST\nfor batch in train_loader:\n    print(batch[0].shape, batch[1].shape, batch[2].shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:34:32.907090Z","iopub.execute_input":"2023-11-23T07:34:32.907467Z","iopub.status.idle":"2023-11-23T07:34:33.056228Z","shell.execute_reply.started":"2023-11-23T07:34:32.907431Z","shell.execute_reply":"2023-11-23T07:34:33.055220Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"torch.Size([256, 56]) torch.Size([256, 56]) torch.Size([256, 56])\n","output_type":"stream"}]},{"cell_type":"code","source":"from pynvml import *\n\n\ndef print_gpu_utilization():\n    nvmlInit()\n    handle = nvmlDeviceGetHandleByIndex(0)\n    info = nvmlDeviceGetMemoryInfo(handle)\n    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:34:33.058907Z","iopub.execute_input":"2023-11-23T07:34:33.059222Z","iopub.status.idle":"2023-11-23T07:34:33.073811Z","shell.execute_reply.started":"2023-11-23T07:34:33.059195Z","shell.execute_reply":"2023-11-23T07:34:33.073086Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from transformers import get_linear_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:34:33.075008Z","iopub.execute_input":"2023-11-23T07:34:33.075335Z","iopub.status.idle":"2023-11-23T07:34:33.086048Z","shell.execute_reply.started":"2023-11-23T07:34:33.075298Z","shell.execute_reply":"2023-11-23T07:34:33.085239Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom transformers import BertForTokenClassification, AdamW\n\nfrom transformers import BertConfig\n\nconfig = BertConfig(\n    hidden_size=512,\n    num_labels=2,  # 2 класса: \"NO\", \"PRIMARY\"\n    output_attentions=False,\n    output_hidden_states=False,\n    num_attention_heads=8,\n    num_hidden_layers=12,\n    max_position_embeddings=60,\n    pad_token_id=0,\n    id2label={\n        \"0\": \"NO\",\n        \"1\": \"PRIMARY\",\n    },\n    label2id={\n        \"NO\": 0,\n        \"PRIMARY\": 1,\n    },\n)\n\nmodel = BertForTokenClassification(config)\nmodel.cuda()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:34:33.087115Z","iopub.execute_input":"2023-11-23T07:34:33.087448Z","iopub.status.idle":"2023-11-23T07:34:40.072648Z","shell.execute_reply.started":"2023-11-23T07:34:33.087414Z","shell.execute_reply":"2023-11-23T07:34:40.071604Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"BertForTokenClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 512, padding_idx=0)\n      (position_embeddings): Embedding(60, 512)\n      (token_type_embeddings): Embedding(2, 512)\n      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=512, out_features=512, bias=True)\n              (key): Linear(in_features=512, out_features=512, bias=True)\n              (value): Linear(in_features=512, out_features=512, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=512, out_features=512, bias=True)\n              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=512, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=512, bias=True)\n            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=512, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\nepochs = 5\n\ntotal_steps = len(train_loader) * epochs\n\nscheduler = get_linear_schedule_with_warmup(optimizer,\n                                            num_warmup_steps = 0,\n                                            num_training_steps = total_steps)\ncriterion = torch.nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:34:40.073988Z","iopub.execute_input":"2023-11-23T07:34:40.074382Z","iopub.status.idle":"2023-11-23T07:34:40.085177Z","shell.execute_reply.started":"2023-11-23T07:34:40.074347Z","shell.execute_reply":"2023-11-23T07:34:40.084239Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\n\n# Function to calculate the accuracy of our predictions vs labels\ndef flat_accuracy(preds, labels, mask):\n    slices = []\n    for m in mask:\n        tmp = np.where(np.flip(m) == 1)[0][0]\n        index_one_from_end = len(m) - 1 - tmp\n        slices.append((1, index_one_from_end))\n        \n    pred_labels = np.argmax(preds, axis=-1)\n    \n    t_pn = 0\n    for i in range(len(labels)):\n        start = slices[i][0]\n        end = slices[i][1]\n        len_ = end - start\n        t_pn += (np.sum(pred_labels[i, start:end] == labels[i, start:end]) == len_)\n\n    return t_pn / labels.shape[0]\n","metadata":{"execution":{"iopub.status.busy":"2023-11-23T07:34:40.086476Z","iopub.execute_input":"2023-11-23T07:34:40.086856Z","iopub.status.idle":"2023-11-23T07:34:40.095128Z","shell.execute_reply.started":"2023-11-23T07:34:40.086823Z","shell.execute_reply":"2023-11-23T07:34:40.094276Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"X = np.array([\n     [[0.3, 0.7],[0.3, 0.7], [0.8, 0.2], [0.8, 0.2],[1.0, 0.7], [0.1, 0.9]],\n     [[0.3, 0.7],[0.6, 0.4], [0.2, 0.8], [0.8, 0.2],[0.3, 0.7], [0.1, 0.9]],\n     [[0.3, 0.7],[0.3, 0.7], [0.8, 0.2], [0.8, 0.2],[0.3, 0.7], [0.1, 0.9]],\n    ])\nMASK = np.array([[1,1,1,1,0,0],\n                 [1,1,1,1,1,0],\n                 [1,1,1,1,1,0]])\n\nY = np.array([[0,1,0,0,0,0],\n              [0,0,1,0,0,0],\n              [0,1,0,0,0,0]])\n\nflat_accuracy(X,Y,MASK)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T08:05:08.901550Z","iopub.execute_input":"2023-11-23T08:05:08.901947Z","iopub.status.idle":"2023-11-23T08:05:08.914010Z","shell.execute_reply.started":"2023-11-23T08:05:08.901915Z","shell.execute_reply":"2023-11-23T08:05:08.912959Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"1.0"},"metadata":{}}]},{"cell_type":"code","source":"# TEST\n#for batch in train_loader:\n#    with torch.no_grad():\n#        output = model(\n#            batch[0].to(device),\n#            token_type_ids=None,\n#            attention_mask=batch[1].to(device),\n#            labels=batch[2].to(device)\n#        )\n#    \n#    logits = output.logits.detach().cpu().numpy()\n#    label_ids = batch[2].to('cpu').numpy()\n#    break\n#","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:54.422974Z","iopub.execute_input":"2023-11-22T15:53:54.423253Z","iopub.status.idle":"2023-11-22T15:53:54.432289Z","shell.execute_reply.started":"2023-11-22T15:53:54.423217Z","shell.execute_reply":"2023-11-22T15:53:54.431341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#logits.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-22T13:34:28.662324Z","iopub.execute_input":"2023-11-22T13:34:28.663135Z","iopub.status.idle":"2023-11-22T13:34:28.669081Z","shell.execute_reply.started":"2023-11-22T13:34:28.663100Z","shell.execute_reply":"2023-11-22T13:34:28.668172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#label_ids.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-22T13:32:56.093179Z","iopub.execute_input":"2023-11-22T13:32:56.093592Z","iopub.status.idle":"2023-11-22T13:32:56.099716Z","shell.execute_reply.started":"2023-11-22T13:32:56.093557Z","shell.execute_reply":"2023-11-22T13:32:56.098795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#np.argmax(logits, axis=-1)[0], label_ids[0]\n","metadata":{"execution":{"iopub.status.busy":"2023-11-22T13:35:51.985250Z","iopub.execute_input":"2023-11-22T13:35:51.986204Z","iopub.status.idle":"2023-11-22T13:35:51.993456Z","shell.execute_reply.started":"2023-11-22T13:35:51.986169Z","shell.execute_reply":"2023-11-22T13:35:51.992510Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport datetime\n\ndef format_time(elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n\n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))","metadata":{"execution":{"iopub.status.busy":"2023-11-23T08:05:05.921634Z","iopub.execute_input":"2023-11-23T08:05:05.922294Z","iopub.status.idle":"2023-11-23T08:05:05.928097Z","shell.execute_reply.started":"2023-11-23T08:05:05.922257Z","shell.execute_reply":"2023-11-23T08:05:05.927087Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"## пайплайн обучения","metadata":{}},{"cell_type":"code","source":"import random\nimport numpy as np\n\n# Set the seed value all over the place to make this reproducible.\nseed_val = 42\n\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\n\n\ntraining_stats = []\n\n\ntotal_t0 = time.time()\n\nfor epoch_i in range(0, epochs):\n\n    print(\"\")\n    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n    print('Training...')\n    t0 = time.time()\n\n    total_train_loss = 0\n    total_train_accuracy = 0\n    \n    model.train()\n\n    for step, batch in enumerate(train_loader):\n        # Progress update every 100 batches.\n        if step % 500 == 0 and not step == 0:\n            # Calculate elapsed time in minutes.\n            elapsed = format_time(time.time() - t0)\n\n            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_loader), elapsed))\n\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        model.zero_grad()\n        output = model(\n            b_input_ids,\n            token_type_ids=None,\n            attention_mask=b_input_mask,\n            labels=b_labels,\n            return_dict=True\n        )\n\n        total_train_loss += output.loss.item()\n\n        output.loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n        \n        logits = output.logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n        b_mask = b_input_mask.to('cpu').numpy()\n\n        batch_acc = flat_accuracy(logits, label_ids, b_mask)\n        if step % 500 == 0 and not step == 0:\n            print(f'  Batch accuracy = {batch_acc} ')\n        total_train_accuracy += batch_acc\n\n\n    avg_train_accuracy = total_train_accuracy / len(train_loader)\n\n    avg_train_loss = total_train_loss / len(train_loader)\n\n    training_time = format_time(time.time() - t0)\n\n    print(\"\")\n    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n    print(\"  Accuracy: {0:.2f}\".format(avg_train_accuracy))\n    print(\"  Training epoch took: {:}\".format(training_time))\n\n    # ========================================\n    #               Validation\n    # ========================================\n\n    print(\"\")\n    print(\"Running Validation...\")\n\n    t0 = time.time()\n\n\n    model.eval()\n\n    # Tracking variables\n    total_eval_accuracy = 0\n    total_eval_loss = 0\n    nb_eval_steps = 0\n\n    # Evaluate data for one epoch\n    for batch in test_loader:\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n\n        with torch.no_grad():\n\n\n            output = model(b_input_ids,\n                           token_type_ids=None,\n                           attention_mask=b_input_mask,\n                           labels=b_labels)\n\n        # Accumulate the validation loss.\n        total_eval_loss += output.loss.item()\n\n        # Move logits and labels to CPU\n        logits = output.logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n        b_mask = b_input_mask.to('cpu').numpy()\n        \n\n        total_eval_accuracy += flat_accuracy(logits, label_ids, b_mask)\n\n\n    avg_val_accuracy = total_eval_accuracy / len(test_loader)\n    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n\n    # Calculate the average loss over all of the batches.\n    avg_val_loss = total_eval_loss / len(test_loader)\n\n    # Measure how long the validation run took.\n    validation_time = format_time(time.time() - t0)\n\n    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n    print(\"  Validation took: {:}\".format(validation_time))\n\n    # Record all statistics from this epoch.\n    training_stats.append(\n        {\n            'epoch': epoch_i + 1,\n            'Training Loss': avg_train_loss,\n            'Valid. Loss': avg_val_loss,\n            'Valid. Accur.': avg_val_accuracy,\n            'Training Time': training_time,\n            'Validation Time': validation_time\n        }\n    )\n\nprint(\"\")\nprint(\"Training complete!\")\n\nprint(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:41:17.859397Z","iopub.execute_input":"2023-11-22T22:41:17.860110Z","iopub.status.idle":"2023-11-23T03:00:41.335848Z","shell.execute_reply.started":"2023-11-22T22:41:17.860076Z","shell.execute_reply":"2023-11-23T03:00:41.334414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Accuracy: 0.91","metadata":{}},{"cell_type":"markdown","source":"* **сохранил веса с прошлого запуска (учил 5 эпох)***","metadata":{}},{"cell_type":"code","source":"model_save_path = \"./bert_model\"","metadata":{"execution":{"iopub.status.busy":"2023-11-23T08:02:36.402742Z","iopub.execute_input":"2023-11-23T08:02:36.403591Z","iopub.status.idle":"2023-11-23T08:02:36.407833Z","shell.execute_reply.started":"2023-11-23T08:02:36.403558Z","shell.execute_reply":"2023-11-23T08:02:36.406620Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained(model_save_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T03:01:05.102324Z","iopub.execute_input":"2023-11-23T03:01:05.102989Z","iopub.status.idle":"2023-11-23T03:01:05.692452Z","shell.execute_reply.started":"2023-11-23T03:01:05.102958Z","shell.execute_reply":"2023-11-23T03:01:05.691447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!zip -r bert_model.zip ./bert_model","metadata":{"execution":{"iopub.status.busy":"2023-11-23T03:04:09.581692Z","iopub.execute_input":"2023-11-23T03:04:09.582318Z","iopub.status.idle":"2023-11-23T03:04:24.499626Z","shell.execute_reply.started":"2023-11-23T03:04:09.582280Z","shell.execute_reply":"2023-11-23T03:04:24.498587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!rm -rf weights.zip","metadata":{"execution":{"iopub.status.busy":"2023-11-23T08:01:52.900323Z","iopub.execute_input":"2023-11-23T08:01:52.900706Z","iopub.status.idle":"2023-11-23T08:01:53.930067Z","shell.execute_reply.started":"2023-11-23T08:01:52.900674Z","shell.execute_reply":"2023-11-23T08:01:53.928759Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1hrLQGpZ_DD1j9n-q7fpAWMEe0mDan7tD' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1hrLQGpZ_DD1j9n-q7fpAWMEe0mDan7tD\" -O weights.zip && rm -rf /tmp/cookies.txt\n!unzip weights.zip","metadata":{"execution":{"iopub.status.busy":"2023-11-23T08:02:02.248635Z","iopub.execute_input":"2023-11-23T08:02:02.249620Z","iopub.status.idle":"2023-11-23T08:02:08.937372Z","shell.execute_reply.started":"2023-11-23T08:02:02.249574Z","shell.execute_reply":"2023-11-23T08:02:08.936223Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"--2023-11-23 08:02:03--  https://docs.google.com/uc?export=download&confirm=t&id=1hrLQGpZ_DD1j9n-q7fpAWMEe0mDan7tD\nResolving docs.google.com (docs.google.com)... 173.194.69.139, 173.194.69.138, 173.194.69.113, ...\nConnecting to docs.google.com (docs.google.com)|173.194.69.139|:443... connected.\nHTTP request sent, awaiting response... 303 See Other\nLocation: https://doc-0o-38-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/fj60tmk38cl6sqhl9stsdilg17emf2k1/1700726475000/09074642392443333439/*/1hrLQGpZ_DD1j9n-q7fpAWMEe0mDan7tD?e=download&uuid=09dc664d-af18-4528-98bf-7b1d1441df9c [following]\nWarning: wildcards not supported in HTTP.\n--2023-11-23 08:02:03--  https://doc-0o-38-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/fj60tmk38cl6sqhl9stsdilg17emf2k1/1700726475000/09074642392443333439/*/1hrLQGpZ_DD1j9n-q7fpAWMEe0mDan7tD?e=download&uuid=09dc664d-af18-4528-98bf-7b1d1441df9c\nResolving doc-0o-38-docs.googleusercontent.com (doc-0o-38-docs.googleusercontent.com)... 108.177.127.132, 2a00:1450:4013:c07::84\nConnecting to doc-0o-38-docs.googleusercontent.com (doc-0o-38-docs.googleusercontent.com)|108.177.127.132|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 245140981 (234M) [application/zip]\nSaving to: ‘weights.zip’\n\nweights.zip         100%[===================>] 233.78M   208MB/s    in 1.1s    \n\n2023-11-23 08:02:05 (208 MB/s) - ‘weights.zip’ saved [245140981/245140981]\n\nArchive:  weights.zip\n   creating: bert_model/\n  inflating: bert_model/model.safetensors  \n  inflating: __MACOSX/bert_model/._model.safetensors  \n  inflating: bert_model/config.json  \n  inflating: __MACOSX/bert_model/._config.json  \n","output_type":"stream"}]},{"cell_type":"code","source":"loaded_model = BertForTokenClassification.from_pretrained(model_save_path)\nloaded_model.cuda()","metadata":{"execution":{"iopub.status.busy":"2023-11-23T08:08:06.159232Z","iopub.execute_input":"2023-11-23T08:08:06.159966Z","iopub.status.idle":"2023-11-23T08:08:06.873665Z","shell.execute_reply.started":"2023-11-23T08:08:06.159932Z","shell.execute_reply":"2023-11-23T08:08:06.872711Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"BertForTokenClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 512, padding_idx=0)\n      (position_embeddings): Embedding(60, 512)\n      (token_type_embeddings): Embedding(2, 512)\n      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=512, out_features=512, bias=True)\n              (key): Linear(in_features=512, out_features=512, bias=True)\n              (value): Linear(in_features=512, out_features=512, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=512, out_features=512, bias=True)\n              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=512, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=512, bias=True)\n            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=512, out_features=2, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"def model_eval(model):\n    print(\"\")\n    print(\"Running Validation...\")\n\n    t0 = time.time()\n    model.eval()\n\n    total_eval_accuracy = 0\n    total_eval_loss = 0\n    nb_eval_steps = 0\n\n    # Evaluate data for one epoch\n    for batch in test_loader:\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n\n        with torch.no_grad():\n\n\n            output = model(b_input_ids,\n                           token_type_ids=None,\n                           attention_mask=b_input_mask,\n                           labels=b_labels)\n\n        # Accumulate the validation loss.\n        total_eval_loss += output.loss.item()\n\n        # Move logits and labels to CPU\n        logits = output.logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n        b_mask = b_input_mask.to('cpu').numpy()\n        \n\n        total_eval_accuracy += flat_accuracy(logits, label_ids, b_mask)\n\n\n    avg_val_accuracy = total_eval_accuracy / len(test_loader)\n    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n\n    # Calculate the average loss over all of the batches.\n    avg_val_loss = total_eval_loss / len(test_loader)\n\n    # Measure how long the validation run took.\n    validation_time = format_time(time.time() - t0)\n\n    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n    print(\"  Validation took: {:}\".format(validation_time))","metadata":{"execution":{"iopub.status.busy":"2023-11-23T08:08:09.173666Z","iopub.execute_input":"2023-11-23T08:08:09.174467Z","iopub.status.idle":"2023-11-23T08:08:09.184587Z","shell.execute_reply.started":"2023-11-23T08:08:09.174427Z","shell.execute_reply":"2023-11-23T08:08:09.183519Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"model_eval(loaded_model)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T08:08:11.544704Z","iopub.execute_input":"2023-11-23T08:08:11.545395Z","iopub.status.idle":"2023-11-23T08:25:40.216465Z","shell.execute_reply.started":"2023-11-23T08:08:11.545360Z","shell.execute_reply":"2023-11-23T08:25:40.215429Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"\nRunning Validation...\n  Accuracy: 0.91\n  Validation Loss: 0.01\n  Validation took: 0:17:29\n","output_type":"stream"}]},{"cell_type":"markdown","source":"*Вот доказательство*","metadata":{}},{"cell_type":"code","source":"def test_suggestion(model, suggestion: str) -> str:\n    word_max_length=56\n    words = suggestion.split()\n    model_max_length = 64\n    chars = \"АаБбВвГгДдЕеЁёЖжЗзИиЙйКкЛлМмНнОоПпРрСсТтУуФфХхЦцЧчШшЩщЪъЫыЬьЭэЮюЯя\"\n    tokenizer = CharacterTokenizer(chars, model_max_length)\n    input_ids = []\n    input_mask = []\n    for word in words:\n        tokens = tokenizer.encode_plus(\n            word,\n            add_special_tokens=True,\n            max_length=max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        input_ids.append(tokens['input_ids'].squeeze(1))\n        input_mask.append(tokens['attention_mask'].squeeze(1))\n    \n    input_ids = torch.stack(input_ids, dim=1).squeeze(0).to(device)\n    input_mask = torch.stack(input_mask, dim=1).squeeze(0).to(device)\n\n    with torch.no_grad():\n        output = model(\n            input_ids,\n            token_type_ids=None,\n            attention_mask=input_mask,\n        )\n    logits = output.logits.detach().cpu().numpy()\n    pred_labels = np.argmax(logits, axis=-1)\n    \n    slices = []\n    for in_m in input_mask:\n        m = np.array(in_m.cpu())\n        tmp = np.where(np.flip(m) == 1)[0][0]\n        index_one_from_end = len(m) - 1 - tmp\n        slices.append((1, index_one_from_end))\n    \n    for i in range(len(words)):\n        start = slices[i][0]\n        end = slices[i][1]\n        predicat = pred_labels[i][start:end]\n        try:\n            stress_index = np.where(np.array(predicat) == 1)[0][0]\n        except:\n            continue\n        \n        words[i] = words[i][:stress_index] + words[i][stress_index].upper() + words[i][stress_index+1:]\n    \n    return \" \".join(words)\n        \n        \n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-23T09:09:22.444973Z","iopub.execute_input":"2023-11-23T09:09:22.445365Z","iopub.status.idle":"2023-11-23T09:09:22.457943Z","shell.execute_reply.started":"2023-11-23T09:09:22.445327Z","shell.execute_reply":"2023-11-23T09:09:22.456906Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"test_suggestion(loaded_model, 'чтобы торты были вкусные нужно добавить сливовый творог')","metadata":{"execution":{"iopub.status.busy":"2023-11-23T09:09:28.058249Z","iopub.execute_input":"2023-11-23T09:09:28.058599Z","iopub.status.idle":"2023-11-23T09:09:28.080757Z","shell.execute_reply.started":"2023-11-23T09:09:28.058571Z","shell.execute_reply":"2023-11-23T09:09:28.079826Z"},"trusted":true},"execution_count":154,"outputs":[{"execution_count":154,"output_type":"execute_result","data":{"text/plain":"'чтОбы тОрты бЫли вкуснЫе нУжно добАвить слИвовый твОрог'"},"metadata":{}}]},{"cell_type":"code","source":"test_suggestion(loaded_model, 'как ставить ударения в разных частях речи')","metadata":{"execution":{"iopub.status.busy":"2023-11-23T09:09:29.092250Z","iopub.execute_input":"2023-11-23T09:09:29.092631Z","iopub.status.idle":"2023-11-23T09:09:29.116235Z","shell.execute_reply.started":"2023-11-23T09:09:29.092596Z","shell.execute_reply":"2023-11-23T09:09:29.115305Z"},"trusted":true},"execution_count":155,"outputs":[{"execution_count":155,"output_type":"execute_result","data":{"text/plain":"'кАк стАвить ударЕния в рАзных чАстях рЕчи'"},"metadata":{}}]}]}