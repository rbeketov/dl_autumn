{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/KuzmaKhrabrov/character-tokenizer.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-22T22:39:33.984178Z","iopub.execute_input":"2023-11-22T22:39:33.984527Z","iopub.status.idle":"2023-11-22T22:39:36.076865Z","shell.execute_reply.started":"2023-11-22T22:39:33.984501Z","shell.execute_reply":"2023-11-22T22:39:36.075877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:39:36.078727Z","iopub.execute_input":"2023-11-22T22:39:36.079021Z","iopub.status.idle":"2023-11-22T22:39:48.566988Z","shell.execute_reply.started":"2023-11-22T22:39:36.078995Z","shell.execute_reply":"2023-11-22T22:39:48.565880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import string\nimport sys\nsys.path.append(\"character-tokenizer\")\nfrom charactertokenizer import CharacterTokenizer\n\nchars = \"АаБбВвГгДдЕеЁёЖжЗзИиЙйКкЛлМмНнОоПпРрСсТтУуФфХхЦцЧчШшЩщЪъЫыЬьЭэЮюЯя\"\nmodel_max_length = 64\ntokenizer = CharacterTokenizer(chars, model_max_length)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:39:48.569197Z","iopub.execute_input":"2023-11-22T22:39:48.569612Z","iopub.status.idle":"2023-11-22T22:39:52.815512Z","shell.execute_reply.started":"2023-11-22T22:39:48.569557Z","shell.execute_reply":"2023-11-22T22:39:52.814764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(chars)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:39:52.816592Z","iopub.execute_input":"2023-11-22T22:39:52.816985Z","iopub.status.idle":"2023-11-22T22:39:52.823775Z","shell.execute_reply.started":"2023-11-22T22:39:52.816959Z","shell.execute_reply":"2023-11-22T22:39:52.822852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example = \"Привет\"\ntokens = tokenizer(example)\nprint(tokens)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:39:52.826082Z","iopub.execute_input":"2023-11-22T22:39:52.826749Z","iopub.status.idle":"2023-11-22T22:39:52.833599Z","shell.execute_reply.started":"2023-11-22T22:39:52.826723Z","shell.execute_reply":"2023-11-22T22:39:52.832770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example = \"Привет\"\ntokens = tokenizer.encode_plus(\n    example,\n    add_special_tokens = True,\n    max_length = 20,\n    padding = 'max_length'\n)\nprint(tokens)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:39:52.834676Z","iopub.execute_input":"2023-11-22T22:39:52.835272Z","iopub.status.idle":"2023-11-22T22:39:52.843601Z","shell.execute_reply.started":"2023-11-22T22:39:52.835241Z","shell.execute_reply":"2023-11-22T22:39:52.842693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!rm -rf all_accents.zip","metadata":{"execution":{"iopub.status.busy":"2023-11-22T19:50:10.082267Z","iopub.execute_input":"2023-11-22T19:50:10.082530Z","iopub.status.idle":"2023-11-22T19:50:10.092352Z","shell.execute_reply.started":"2023-11-22T19:50:10.082506Z","shell.execute_reply":"2023-11-22T19:50:10.091486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://github.com/Koziev/NLP_Datasets/raw/master/Stress/all_accents.zip\n!unzip all_accents.zip","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:39:52.844802Z","iopub.execute_input":"2023-11-22T22:39:52.845510Z","iopub.status.idle":"2023-11-22T22:39:56.304167Z","shell.execute_reply.started":"2023-11-22T22:39:52.845485Z","shell.execute_reply":"2023-11-22T22:39:56.303146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfile_path = 'all_accents.tsv'\ndf = pd.read_csv(file_path, delimiter='\\t')\n\ndf.sample(20)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:39:56.306492Z","iopub.execute_input":"2023-11-22T22:39:56.306851Z","iopub.status.idle":"2023-11-22T22:39:59.904472Z","shell.execute_reply.started":"2023-11-22T22:39:56.306822Z","shell.execute_reply":"2023-11-22T22:39:59.903617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:39:59.906340Z","iopub.execute_input":"2023-11-22T22:39:59.906790Z","iopub.status.idle":"2023-11-22T22:39:59.912731Z","shell.execute_reply.started":"2023-11-22T22:39:59.906747Z","shell.execute_reply":"2023-11-22T22:39:59.911814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length = df['-де'].apply(len).max()\n\nlongest_string = df[df['-де'].apply(len) == max_length]['-де'].values[0]\n\nprint(\"Самая длинная строка:\", longest_string)\nprint(\"Длина строки:\", max_length)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:40:03.547551Z","iopub.execute_input":"2023-11-22T22:40:03.548588Z","iopub.status.idle":"2023-11-22T22:40:05.218989Z","shell.execute_reply.started":"2023-11-22T22:40:03.548534Z","shell.execute_reply":"2023-11-22T22:40:05.217932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.iloc[624999]","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:40:05.372899Z","iopub.execute_input":"2023-11-22T22:40:05.373710Z","iopub.status.idle":"2023-11-22T22:40:05.380611Z","shell.execute_reply.started":"2023-11-22T22:40:05.373679Z","shell.execute_reply":"2023-11-22T22:40:05.379635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Жесткач :)*","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:40:07.962707Z","iopub.execute_input":"2023-11-22T22:40:07.963417Z","iopub.status.idle":"2023-11-22T22:40:07.967312Z","shell.execute_reply.started":"2023-11-22T22:40:07.963390Z","shell.execute_reply":"2023-11-22T22:40:07.966410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:40:09.294695Z","iopub.execute_input":"2023-11-22T22:40:09.295062Z","iopub.status.idle":"2023-11-22T22:40:09.833860Z","shell.execute_reply.started":"2023-11-22T22:40:09.295034Z","shell.execute_reply":"2023-11-22T22:40:09.832788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class StressDataset(Dataset):\n    def __init__(self, file_path, max_length=56, test_size=0.5, random_seed=42):\n        self.df = pd.read_csv(file_path, delimiter='\\t')\n        self.chars = \"АаБбВвГгДдЕеЁёЖжЗзИиЙйКкЛлМмНнОоПпРрСсТтУуФфХхЦцЧчШшЩщЪъЫыЬьЭэЮюЯя\"\n        self.model_max_length = 64\n        self.tokenizer = CharacterTokenizer(self.chars, self.model_max_length)\n        self.word_max_length = max_length\n\n        self.train_data_index, self.test_data_index = (\n            train_test_split(\n                self.df.index,\n                test_size=test_size,\n                random_state=random_seed\n            )\n        )\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        text = self.df.loc[idx, '-де']\n        label = self.df.loc[idx, '-д^е']\n\n        tokens = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.word_max_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n        # [CLS]востфак[SEP][PAD]...[PAD]\n        # востфак востф^ак\n        number_stress_token = label.find('^') + 1\n        labels = [0]*len(tokens['attention_mask'].squeeze())\n        labels[number_stress_token] = 1\n        \n        labels = torch.tensor(labels, dtype=torch.long)\n        tokens['labels'] = labels\n        return tokens\n        ","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:40:11.236389Z","iopub.execute_input":"2023-11-22T22:40:11.237264Z","iopub.status.idle":"2023-11-22T22:40:11.246855Z","shell.execute_reply.started":"2023-11-22T22:40:11.237226Z","shell.execute_reply":"2023-11-22T22:40:11.245902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = 'all_accents.tsv'\nstress_dataset = StressDataset(file_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:40:13.479068Z","iopub.execute_input":"2023-11-22T22:40:13.479444Z","iopub.status.idle":"2023-11-22T22:40:16.481300Z","shell.execute_reply.started":"2023-11-22T22:40:13.479415Z","shell.execute_reply":"2023-11-22T22:40:16.480516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INDEX = 107500\nword_tokens = stress_dataset[INDEX]\n(\nword_tokens['labels'],\ndf.iloc[INDEX].values[0],\ndf.iloc[INDEX].values[1],\ntokenizer.decode(word_tokens['input_ids'].squeeze().tolist())\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:40:16.482693Z","iopub.execute_input":"2023-11-22T22:40:16.482977Z","iopub.status.idle":"2023-11-22T22:40:26.157762Z","shell.execute_reply.started":"2023-11-22T22:40:16.482953Z","shell.execute_reply":"2023-11-22T22:40:26.156834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Subset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:40:26.159913Z","iopub.execute_input":"2023-11-22T22:40:26.160639Z","iopub.status.idle":"2023-11-22T22:40:26.165219Z","shell.execute_reply.started":"2023-11-22T22:40:26.160601Z","shell.execute_reply":"2023-11-22T22:40:26.164205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = 'all_accents.tsv'\nstress_dataset = StressDataset(file_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:40:26.166652Z","iopub.execute_input":"2023-11-22T22:40:26.167021Z","iopub.status.idle":"2023-11-22T22:40:29.297820Z","shell.execute_reply.started":"2023-11-22T22:40:26.166987Z","shell.execute_reply":"2023-11-22T22:40:29.296454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collate_fn(batch):\n    input_ids = torch.stack([sample['input_ids'] for sample in batch])\n    attention_mask = torch.stack([sample['attention_mask'] for sample in batch])\n    labels = torch.stack([sample['labels'] for sample in batch])\n\n    return [input_ids.squeeze(1), attention_mask.squeeze(1), labels]\n\nbatch_size = 256\n\ntrain_loader = DataLoader(\n    Subset(stress_dataset, stress_dataset.train_data_index),\n    batch_size=batch_size,\n    shuffle=True,\n    drop_last = True,\n    collate_fn = collate_fn,\n)\n\ntest_loader = DataLoader(\n    Subset(stress_dataset, stress_dataset.test_data_index),\n    batch_size=batch_size,\n    shuffle=False,\n    collate_fn = collate_fn,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:40:29.299962Z","iopub.execute_input":"2023-11-22T22:40:29.300776Z","iopub.status.idle":"2023-11-22T22:40:29.309831Z","shell.execute_reply.started":"2023-11-22T22:40:29.300746Z","shell.execute_reply":"2023-11-22T22:40:29.307136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n\n    # Tell PyTorch to use the GPU.\n    device = torch.device(\"cuda\")\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n\n# If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:40:29.310876Z","iopub.execute_input":"2023-11-22T22:40:29.311188Z","iopub.status.idle":"2023-11-22T22:40:29.371810Z","shell.execute_reply.started":"2023-11-22T22:40:29.311162Z","shell.execute_reply":"2023-11-22T22:40:29.370711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers\n!pip install pynvml","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:40:29.373607Z","iopub.execute_input":"2023-11-22T22:40:29.373986Z","iopub.status.idle":"2023-11-22T22:40:52.550231Z","shell.execute_reply.started":"2023-11-22T22:40:29.373951Z","shell.execute_reply":"2023-11-22T22:40:52.548792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TEST\ncnt = 0\nfor batch in train_loader:\n    print(len(batch[0]), len(batch[1]), len(batch[2]))\n    print(type(batch[0]), type(batch[1]), type(batch[2]))\n    cnt += 1\n    if cnt == 3:\n        break","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:40:52.553778Z","iopub.execute_input":"2023-11-22T22:40:52.554140Z","iopub.status.idle":"2023-11-22T22:40:52.887505Z","shell.execute_reply.started":"2023-11-22T22:40:52.554107Z","shell.execute_reply":"2023-11-22T22:40:52.886502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TEST\nfor batch in train_loader:\n    print(batch[0].shape, batch[1].shape, batch[2].shape)\n    break","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:40:52.888845Z","iopub.execute_input":"2023-11-22T22:40:52.889160Z","iopub.status.idle":"2023-11-22T22:40:53.042435Z","shell.execute_reply.started":"2023-11-22T22:40:52.889135Z","shell.execute_reply":"2023-11-22T22:40:53.041486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pynvml import *\n\n\ndef print_gpu_utilization():\n    nvmlInit()\n    handle = nvmlDeviceGetHandleByIndex(0)\n    info = nvmlDeviceGetMemoryInfo(handle)\n    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:40:53.043836Z","iopub.execute_input":"2023-11-22T22:40:53.044205Z","iopub.status.idle":"2023-11-22T22:40:53.060122Z","shell.execute_reply.started":"2023-11-22T22:40:53.044172Z","shell.execute_reply":"2023-11-22T22:40:53.059369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import get_linear_schedule_with_warmup","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:40:53.061348Z","iopub.execute_input":"2023-11-22T22:40:53.061816Z","iopub.status.idle":"2023-11-22T22:40:53.071935Z","shell.execute_reply.started":"2023-11-22T22:40:53.061774Z","shell.execute_reply":"2023-11-22T22:40:53.071110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom transformers import BertForTokenClassification, AdamW\n\nfrom transformers import BertConfig\n\nconfig = BertConfig(\n    hidden_size=512,\n    num_labels=2,  # 2 класса: \"NO\", \"PRIMARY\"\n    output_attentions=False,\n    output_hidden_states=False,\n    num_attention_heads=8,\n    num_hidden_layers=12,\n    max_position_embeddings=60,\n    pad_token_id=0,\n    id2label={\n        \"0\": \"NO\",\n        \"1\": \"PRIMARY\",\n    },\n    label2id={\n        \"NO\": 0,\n        \"PRIMARY\": 1,\n    },\n)\n\nmodel = BertForTokenClassification(config)\nmodel.cuda()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:40:53.073027Z","iopub.execute_input":"2023-11-22T22:40:53.073287Z","iopub.status.idle":"2023-11-22T22:40:59.363498Z","shell.execute_reply.started":"2023-11-22T22:40:53.073264Z","shell.execute_reply":"2023-11-22T22:40:59.362515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\nepochs = 5\n\ntotal_steps = len(train_loader) * epochs\n\nscheduler = get_linear_schedule_with_warmup(optimizer,\n                                            num_warmup_steps = 0,\n                                            num_training_steps = total_steps)\ncriterion = torch.nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:41:07.120933Z","iopub.execute_input":"2023-11-22T22:41:07.121836Z","iopub.status.idle":"2023-11-22T22:41:07.132990Z","shell.execute_reply.started":"2023-11-22T22:41:07.121803Z","shell.execute_reply":"2023-11-22T22:41:07.131826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Function to calculate the accuracy of our predictions vs labels\ndef flat_accuracy(preds, labels, mask):\n    slices = []\n    for m in mask:\n        tmp = np.where(np.flip(m) == 1)[0][0]\n        index_one_from_end = len(m) - 1 - tmp\n        slices.append((1, index_one_from_end))\n        \n    pred_labels = np.argmax(preds, axis=-1)\n    \n    t_pn = 0\n    for i in range(len(labels)):\n        start = slices[i][0]\n        end = slices[i][1]\n        len_ = end - start\n        t_pn += (np.sum(pred_labels[i, start:end] == labels[i, start:end]) == len_)\n\n    return t_pn / labels.shape[0]\n","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:41:10.545508Z","iopub.execute_input":"2023-11-22T22:41:10.545867Z","iopub.status.idle":"2023-11-22T22:41:10.553617Z","shell.execute_reply.started":"2023-11-22T22:41:10.545842Z","shell.execute_reply":"2023-11-22T22:41:10.552539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-22T20:02:45.954824Z","iopub.execute_input":"2023-11-22T20:02:45.955235Z","iopub.status.idle":"2023-11-22T20:02:45.961387Z","shell.execute_reply.started":"2023-11-22T20:02:45.955206Z","shell.execute_reply":"2023-11-22T20:02:45.960480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.array([\n     [[0.3, 0.7],[0.3, 0.7], [0.8, 0.2], [0.8, 0.2],[1.0, 0.7], [0.1, 0.9]],\n     [[0.3, 0.7],[0.6, 0.4], [0.2, 0.8], [0.8, 0.2],[0.3, 0.7], [0.1, 0.9]],\n     [[0.3, 0.7],[0.3, 0.7], [0.8, 0.2], [0.8, 0.2],[0.3, 0.7], [0.1, 0.9]],\n    ])\nMASK = np.array([[1,1,1,1,0,0],\n                 [1,1,1,1,1,0],\n                 [1,1,1,1,1,0]])\n\nY = np.array([[0,1,0,0,0,0],\n              [0,0,1,0,0,0],\n              [0,1,0,0,0,0]])\n\nflat_accuracy(X,Y,MASK)","metadata":{"execution":{"iopub.status.busy":"2023-11-22T20:02:46.831081Z","iopub.execute_input":"2023-11-22T20:02:46.831463Z","iopub.status.idle":"2023-11-22T20:02:46.843368Z","shell.execute_reply.started":"2023-11-22T20:02:46.831431Z","shell.execute_reply":"2023-11-22T20:02:46.842436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TEST\n#for batch in train_loader:\n#    with torch.no_grad():\n#        output = model(\n#            batch[0].to(device),\n#            token_type_ids=None,\n#            attention_mask=batch[1].to(device),\n#            labels=batch[2].to(device)\n#        )\n#    \n#    logits = output.logits.detach().cpu().numpy()\n#    label_ids = batch[2].to('cpu').numpy()\n#    break\n#","metadata":{"execution":{"iopub.status.busy":"2023-11-22T15:53:54.422974Z","iopub.execute_input":"2023-11-22T15:53:54.423253Z","iopub.status.idle":"2023-11-22T15:53:54.432289Z","shell.execute_reply.started":"2023-11-22T15:53:54.423217Z","shell.execute_reply":"2023-11-22T15:53:54.431341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#logits.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-22T13:34:28.662324Z","iopub.execute_input":"2023-11-22T13:34:28.663135Z","iopub.status.idle":"2023-11-22T13:34:28.669081Z","shell.execute_reply.started":"2023-11-22T13:34:28.663100Z","shell.execute_reply":"2023-11-22T13:34:28.668172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#label_ids.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-22T13:32:56.093179Z","iopub.execute_input":"2023-11-22T13:32:56.093592Z","iopub.status.idle":"2023-11-22T13:32:56.099716Z","shell.execute_reply.started":"2023-11-22T13:32:56.093557Z","shell.execute_reply":"2023-11-22T13:32:56.098795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#np.argmax(logits, axis=-1)[0], label_ids[0]\n","metadata":{"execution":{"iopub.status.busy":"2023-11-22T13:35:51.985250Z","iopub.execute_input":"2023-11-22T13:35:51.986204Z","iopub.status.idle":"2023-11-22T13:35:51.993456Z","shell.execute_reply.started":"2023-11-22T13:35:51.986169Z","shell.execute_reply":"2023-11-22T13:35:51.992510Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport datetime\n\ndef format_time(elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n\n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:41:16.396781Z","iopub.execute_input":"2023-11-22T22:41:16.397151Z","iopub.status.idle":"2023-11-22T22:41:16.402721Z","shell.execute_reply.started":"2023-11-22T22:41:16.397121Z","shell.execute_reply":"2023-11-22T22:41:16.401756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## пайплайн обучения","metadata":{}},{"cell_type":"code","source":"import random\nimport numpy as np\n\n# Set the seed value all over the place to make this reproducible.\nseed_val = 42\n\nrandom.seed(seed_val)\nnp.random.seed(seed_val)\ntorch.manual_seed(seed_val)\ntorch.cuda.manual_seed_all(seed_val)\n\n\ntraining_stats = []\n\n\ntotal_t0 = time.time()\n\nfor epoch_i in range(0, epochs):\n\n    print(\"\")\n    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n    print('Training...')\n    t0 = time.time()\n\n    total_train_loss = 0\n    total_train_accuracy = 0\n    \n    model.train()\n\n    for step, batch in enumerate(train_loader):\n        # Progress update every 100 batches.\n        if step % 500 == 0 and not step == 0:\n            # Calculate elapsed time in minutes.\n            elapsed = format_time(time.time() - t0)\n\n            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_loader), elapsed))\n\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        model.zero_grad()\n        output = model(\n            b_input_ids,\n            token_type_ids=None,\n            attention_mask=b_input_mask,\n            labels=b_labels,\n            return_dict=True\n        )\n\n        total_train_loss += output.loss.item()\n\n        output.loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n        \n        logits = output.logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n        b_mask = b_input_mask.to('cpu').numpy()\n\n        batch_acc = flat_accuracy(logits, label_ids, b_mask)\n        if step % 500 == 0 and not step == 0:\n            print(f'  Batch accuracy = {batch_acc} ')\n        total_train_accuracy += batch_acc\n\n\n    avg_train_accuracy = total_train_accuracy / len(train_loader)\n\n    avg_train_loss = total_train_loss / len(train_loader)\n\n    training_time = format_time(time.time() - t0)\n\n    print(\"\")\n    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n    print(\"  Accuracy: {0:.2f}\".format(avg_train_accuracy))\n    print(\"  Training epoch took: {:}\".format(training_time))\n\n    # ========================================\n    #               Validation\n    # ========================================\n\n    print(\"\")\n    print(\"Running Validation...\")\n\n    t0 = time.time()\n\n\n    model.eval()\n\n    # Tracking variables\n    total_eval_accuracy = 0\n    total_eval_loss = 0\n    nb_eval_steps = 0\n\n    # Evaluate data for one epoch\n    for batch in test_loader:\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n\n        with torch.no_grad():\n\n\n            output = model(b_input_ids,\n                           token_type_ids=None,\n                           attention_mask=b_input_mask,\n                           labels=b_labels)\n\n        # Accumulate the validation loss.\n        total_eval_loss += output.loss.item()\n\n        # Move logits and labels to CPU\n        logits = output.logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n        b_mask = b_input_mask.to('cpu').numpy()\n        \n\n        total_eval_accuracy += flat_accuracy(logits, label_ids, b_mask)\n\n\n    avg_val_accuracy = total_eval_accuracy / len(test_loader)\n    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n\n    # Calculate the average loss over all of the batches.\n    avg_val_loss = total_eval_loss / len(test_loader)\n\n    # Measure how long the validation run took.\n    validation_time = format_time(time.time() - t0)\n\n    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n    print(\"  Validation took: {:}\".format(validation_time))\n\n    # Record all statistics from this epoch.\n    training_stats.append(\n        {\n            'epoch': epoch_i + 1,\n            'Training Loss': avg_train_loss,\n            'Valid. Loss': avg_val_loss,\n            'Valid. Accur.': avg_val_accuracy,\n            'Training Time': training_time,\n            'Validation Time': validation_time\n        }\n    )\n\nprint(\"\")\nprint(\"Training complete!\")\n\nprint(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))","metadata":{"execution":{"iopub.status.busy":"2023-11-22T22:41:17.859397Z","iopub.execute_input":"2023-11-22T22:41:17.860110Z","iopub.status.idle":"2023-11-23T03:00:41.335848Z","shell.execute_reply.started":"2023-11-22T22:41:17.860076Z","shell.execute_reply":"2023-11-23T03:00:41.334414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Accuracy: 0.91","metadata":{}},{"cell_type":"code","source":"model_save_path = \"./bert_model\"\n\nmodel.save_pretrained(model_save_path)","metadata":{"execution":{"iopub.status.busy":"2023-11-23T03:01:05.102324Z","iopub.execute_input":"2023-11-23T03:01:05.102989Z","iopub.status.idle":"2023-11-23T03:01:05.692452Z","shell.execute_reply.started":"2023-11-23T03:01:05.102958Z","shell.execute_reply":"2023-11-23T03:01:05.691447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!zip -r bert_model.zip ./bert_model","metadata":{"execution":{"iopub.status.busy":"2023-11-23T03:04:09.581692Z","iopub.execute_input":"2023-11-23T03:04:09.582318Z","iopub.status.idle":"2023-11-23T03:04:24.499626Z","shell.execute_reply.started":"2023-11-23T03:04:09.582280Z","shell.execute_reply":"2023-11-23T03:04:24.498587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_suggestion(suggestion: str) -> str:\n    word_max_length=56\n    words = suggestion.split()\n    model_max_length = 64\n    chars = \"АаБбВвГгДдЕеЁёЖжЗзИиЙйКкЛлМмНнОоПпРрСсТтУуФфХхЦцЧчШшЩщЪъЫыЬьЭэЮюЯя\"\n    tokenizer = CharacterTokenizer(chars, model_max_length)\n    tokens = tokenizer.encode_plus(\n        words,\n        add_special_tokens=True,\n        max_length=max_length,\n        padding='max_length',\n        truncation=True,\n        return_tensors='pt'\n    )\n    \n    input_ids = tokens['input_ids'].squeeze(1)\n    input_mask = tokens['attention_mask'].squeeze(1)\n    with torch.no_grad():\n        output = model(\n            input_ids,\n            token_type_ids=None,\n            attention_mask=input_mask,\n        )\n    logits = output.logits.detach().cpu().numpy()\n    pred_labels = np.argmax(logits, axis=-1)\n    print(pred_labels)\n    ","metadata":{},"execution_count":null,"outputs":[]}]}